{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1066 entries, 0 to 1065\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   restaurant  1066 non-null   object \n",
      " 1   item        1066 non-null   object \n",
      " 2   calories    1066 non-null   float64\n",
      " 3   sodium      1066 non-null   float64\n",
      " 4   sugar       1066 non-null   float64\n",
      " 5   total_fat   1066 non-null   float64\n",
      " 6   protein     1066 non-null   float64\n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 58.4+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataDF = pd.read_csv('./Hamburger.csv', encoding='latin1')\n",
    "dataDF.info()\n",
    "\n",
    "dataDF['restaurant'].replace('macdonald','McDonalds',inplace=True)\n",
    "dataDF['restaurant'].replace('Mcdonald','McDonalds',inplace=True)\n",
    "dataDF['restaurant'].replace('Mcdonalds','McDonalds',inplace=True)\n",
    "dataDF['restaurant'].replace('burgerking','Burger King',inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복값 제거 - 2개 \n",
    "dataDF.duplicated().sum()\n",
    "dataDF.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "restaurant    0\n",
       "item          0\n",
       "calories      0\n",
       "sodium        0\n",
       "sugar         0\n",
       "total_fat     0\n",
       "protein       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 제거 - protein - 94개\n",
    "dataDF.isna().sum()\n",
    "#dataDF.dropna(subset = 'protein',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KNeighborsRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 여러 모델 인스턴스 생성\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m knn \u001b[38;5;241m=\u001b[39m \u001b[43mKNeighborsRegressor\u001b[49m(n_neighbors\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6\u001b[39m)\n\u001b[0;32m      3\u001b[0m knn\u001b[38;5;241m.\u001b[39mfit(xtrain, ytrain)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#%%\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'KNeighborsRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "# 여러 모델 인스턴스 생성\n",
    "knn = KNeighborsRegressor(n_neighbors= 6)\n",
    "knn.fit(xtrain, ytrain)\n",
    "#%%\n",
    "li = LinearRegression()\n",
    "li.fit(xtrain, ytrain)\n",
    "#%%\n",
    "ridge = Ridge()\n",
    "ridge.fit(xtrain, ytrain)\n",
    "#%%\n",
    "lasso = Lasso()\n",
    "lasso.fit(xtrain,ytrain)\n",
    "#%%\n",
    "svr = SVR()\n",
    "svr.fit(xtrain, ytrain)\n",
    "#%%\n",
    "estimators = [('LI', li), ('KNN', knn),('Rige', ridge), ('Lasso',lasso), ('SVR', svr)]\n",
    "\n",
    "voting_models = {'models' :[],'train_score':[],'test_score':[]}\n",
    "for n, model1 in enumerate(estimators[:-1]):\n",
    "    for model2 in estimators[n+1:]:\n",
    "        vt_models = VotingRegressor(estimators=[model1,model2])\n",
    "        vt_models.fit(xtrain, ytrain)\n",
    "        voting_models['models'].append([model1[1],model2[1]])\n",
    "        voting_models['train_score'].append(vt_models.score(xtrain,ytrain))\n",
    "        voting_models['test_score'].append(vt_models.score(xtest,ytest))\n",
    "pd.DataFrame(voting_models)\n",
    "#%%\n",
    "for n1, model1 in enumerate(estimators[:]):\n",
    "    if n1== 3:  # Stop before including 'SVR'\n",
    "        break\n",
    "for n2,model2 in enumerate(estimators[n1 + 1:-1]):  # Iterate from the next model onwards\n",
    "    for model3 in estimators[n2+1:-2]:\n",
    "        vt_models = VotingRegressor(estimators=[model1, model2, model3])\n",
    "        vt_models.fit(xtrain, ytrain)  # Assuming you have xtrain and ytrain defined\n",
    "        voting_models['models'].append([model1[1], model2[1], model3[1]])\n",
    "        voting_models['train_score'].append(vt_models.score(xtrain, ytrain))\n",
    "        voting_models['test_score'].append(vt_models.score(xtest, ytest))\n",
    "pd.DataFrame(voting_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KernelRidge(alpha=0.9, gamma=0.001, kernel=&#x27;poly&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KernelRidge</label><div class=\"sk-toggleable__content\"><pre>KernelRidge(alpha=0.9, gamma=0.001, kernel=&#x27;poly&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KernelRidge(alpha=0.9, gamma=0.001, kernel='poly')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import load\n",
    "\n",
    "model=load(\"./model/KernelRidge.pkl\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "              << 햄버거 먹고 싶니?? >>      \n",
      "    ...    ...   ...    ...    ...   ...    ...   \n",
      ".                                                 \n",
      ". ..   ...    ...    ..    ...    ...    ..    .. \n",
      "                                .     .     .     \n",
      "    ...    ...                       ...    ...   \n",
      ". .     .           :r1SqSK5jr.           .     . \n",
      ". ..   ...      iKgBBB2Lru7jKQBBQJ.      ..    .. \n",
      "    . .       rBBKXjr.   i      rDBB.       . .   \n",
      "    ...      BBr v.   .s  .j.      UBS      ...   \n",
      ". .     .   BB :.                    QK   .     . \n",
      ". .    ...  B7                       PB  ...   .. \n",
      "    . .     UBQMBQBQBdQBBQBQMEBBBQBMBBr     . .   \n",
      "     .      BJ     vBu. .:. :dR:     RB     ..    \n",
      ". .     ..  LM112JvidBB7  :XBBjiLsUu1Qi  ..    .. \n",
      "         .   rBBBBQBBBBBQBQBBBBBBBQBQ.   .     .. \n",
      "    ...     BM. ..:.. ..rv:.  r:.i::rQg     ...   \n",
      "            QS                r:.7iiiBB           \n",
      ". .    ...  .BBI2YYv12IuYLYuPgX251KPBB   ..    .. \n",
      "         .    i1u212u2uUUUU1sYvLvLvv.             \n",
      "    ...    ..                         ..    ...   \n",
      "                                                  \n",
      ". .    ...    ...    ..    ...    ...    ..    .. \n",
      "                                                  \n",
      "    ...    ..    ...    ...    ..    ...    ...   \n",
      "====================================================================================\n",
      "종료키 : 0\n",
      "사용할 모델을 선택하세요~\n",
      "1. BayesianRidge\n",
      "2. KernelRidge\n",
      "3. Lasso\n",
      "4. LassoCV\n",
      "5. LassoLars\n",
      "6. Ridge\n",
      "7. RidgeCV\n",
      "8. KNeighborsRegressor\n",
      "9. LinearRegression\n",
      "10. Boosting\n",
      "11. Decision_tree\n",
      "12. RandomForest\n",
      "13. Voting\n",
      "====================================================================================\n",
      "====================================================================================\n",
      "\n",
      "**Lasso:**\n",
      "\n",
      "**설명:** Lasso는 L1 규제를 사용하는 선형 회귀 모델로, 특정 특징들의 가중치를 0으로 만들어 특징 선택에 활용됩니다.\n",
      "\n",
      "**하이퍼파라미터:** alpha (규제 강도).\n",
      "Lasso모델 불러오기...(성공!)\n",
      "====================================================================================\n",
      "====================================================================================\n",
      "====================================================================================\n",
      "총 7건의 음식이 검색되었습니다! \n",
      "====================================================================================\n"
     ]
    }
   ],
   "source": [
    "from joblib import load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Scaler fitting\n",
    "df=pd.read_csv('./Hamburger.csv')\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(df[[\"sodium\", \"sugar\", \"total_fat\", \"protein\"]])\n",
    "hamburger='''   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "              << 햄버거 먹고 싶니?? >>      \n",
    "    ...    ...   ...    ...    ...   ...    ...   \n",
    ".                                                 \n",
    ". ..   ...    ...    ..    ...    ...    ..    .. \n",
    "                                .     .     .     \n",
    "    ...    ...                       ...    ...   \n",
    ". .     .           :r1SqSK5jr.           .     . \n",
    ". ..   ...      iKgBBB2Lru7jKQBBQJ.      ..    .. \n",
    "    . .       rBBKXjr.   i      rDBB.       . .   \n",
    "    ...      BBr v.   .s  .j.      UBS      ...   \n",
    ". .     .   BB :.                    QK   .     . \n",
    ". .    ...  B7                       PB  ...   .. \n",
    "    . .     UBQMBQBQBdQBBQBQMEBBBQBMBBr     . .   \n",
    "     .      BJ     vBu. .:. :dR:     RB     ..    \n",
    ". .     ..  LM112JvidBB7  :XBBjiLsUu1Qi  ..    .. \n",
    "         .   rBBBBQBBBBBQBQBBBBBBBQBQ.   .     .. \n",
    "    ...     BM. ..:.. ..rv:.  r:.i::rQg     ...   \n",
    "            QS                r:.7iiiBB           \n",
    ". .    ...  .BBI2YYv12IuYLYuPgX251KPBB   ..    .. \n",
    "         .    i1u212u2uUUUU1sYvLvLvv.             \n",
    "    ...    ..                         ..    ...   \n",
    "                                                  \n",
    ". .    ...    ...    ..    ...    ...    ..    .. \n",
    "                                                  \n",
    "    ...    ..    ...    ...    ..    ...    ...   \n",
    "'''\n",
    "\n",
    "model_list=[\"BayesianRidge\",\"KernelRidge\",\"Lasso\",\"LassoCV\",\"LassoLars\",\"Ridge\",\"RidgeCV\",\"KNeighborsRegressor\",\"LinearRegression\",\"Boosting\",\"Decision_tree\",\"RandomForest\",\"Voting\"]\n",
    "model_text=['''**BayesianRidge:**\n",
    "\n",
    "**설명:** BayesianRidge는 베이지안 회귀 모델로, 가중치에 대한 사전 분포를 정의하고 베이지안 추론을 사용하여 가중치를 조절하는 회귀 모델입니다. 오차 항과 가중치에 대한 확률 분포를 고려하여 모델링됩니다.\n",
    "\n",
    "**하이퍼파라미터:** alpha_1, alpha_2, lambda_1, lambda_2, alpha_init, lambda_init 등.\n",
    "''',\n",
    "'''\n",
    "**KernelRidge:**\n",
    "\n",
    "**설명:** KernelRidge는 커널 트릭을 사용하는 Ridge 회귀의 확장입니다. 비선형 데이터를 모델링할 수 있도록 다양한 커널 함수를 사용할 수 있습니다.\n",
    "\n",
    "**하이퍼파라미터:** alpha, kernel, gamma 등.''',\n",
    "'''\n",
    "**Lasso:**\n",
    "\n",
    "**설명:** Lasso는 L1 규제를 사용하는 선형 회귀 모델로, 특정 특징들의 가중치를 0으로 만들어 특징 선택에 활용됩니다.\n",
    "\n",
    "**하이퍼파라미터:** alpha (규제 강도).''',\n",
    "'''\n",
    "**LassoCV:**\n",
    "\n",
    "**설명:** LassoCV는 교차 검증을 사용하여 최적의 alpha 값을 자동으로 찾아주는 Lasso 모델입니다.\n",
    "\n",
    "**하이퍼파라미터:** eps, n_alphas, cv 등''',\n",
    "'''\n",
    "**LassoLars:**\n",
    "\n",
    "**설명:** LassoLars는 Least Angle Regression (LARS) 알고리즘을 사용하는 Lasso 모델로, 계수의 추정치를 조절하면서 변수를 선택할 수 있습니다.\n",
    "\n",
    "**하이퍼파라미터:** alpha (규제 강도).''',\n",
    "'''\n",
    "**Ridge:**\n",
    "\n",
    "**설명:** Ridge는 L2 규제를 사용하여 선형 회귀 모델을 구축합니다. Lasso와 달리 계수를 0에 가깝게 만들지 않고, 작은 값을 유지합니다.\n",
    "\n",
    "**하이퍼파라미터:** alpha (규제 강도)..''',\n",
    "'''\n",
    "**RidgeCV:**\n",
    "\n",
    "**설명:** RidgeCV는 교차 검증을 사용하여 최적의 alpha 값을 자동으로 찾아주는 Ridge 모델입니다.\n",
    "\n",
    "**하이퍼파라미터:** store_cv_values, alphas 등.''',\n",
    "'''\n",
    "**KNR (K-neighbors regression):**\n",
    "\n",
    "**설명:** KNR은 K-최근접 이웃 알고리즘을 사용한 회귀 모델로, 주어진 데이터 포인트에 가장 가까운 K개의 이웃의 평균값이나 가중 평균값을 사용하여 예측을 수행합니다.\n",
    "\n",
    "**하이퍼파라미터:** n_neighbors, weights, algorithm 등.\n",
    "''',\n",
    "'''\n",
    "**LR (Linear Regression):**\n",
    "\n",
    "**설명:** Linear Regression은 선형 모델로, 입력 특징과 가중치의 선형 조합으로 예측을 수행하는 회귀 알고리즘입니다. 가장 간단하면서도 효과적인 회귀 방법 중 하나입니다.\n",
    "\n",
    "**하이퍼파라미터:** 없음 (주로 최소제곱법을 사용하며, 규제를 위한 하이퍼파라미터가 없을 수 있음).\n",
    "''',\n",
    "'''\n",
    "**Boosting:**\n",
    "\n",
    "**설명:** Boosting은 약한 학습자(weak learner)들을 결합하여 강력한 앙상블 모델을 만드는 알고리즘입니다. 이전 학습자의 오차에 가중치를 부여하면서 순차적으로 학습을 진행하여 모델의 성능을 향상시킵니다.\n",
    "\n",
    "**하이퍼파라미터:** n_estimators, learning_rate, max_depth 등.\n",
    "''',\n",
    "'''\n",
    "**Decision_tree:**\n",
    "\n",
    "**설명:** Decision Tree는 데이터를 분할하고 각 분할에서 예측을 수행하는 트리 구조의 모델입니다. 각 분할은 특정 조건을 기반으로 결정되며, 데이터를 계층적으로 분류하여 의사 결정을 수행합니다.\n",
    "\n",
    "**하이퍼파라미터:** max_depth, min_samples_split, min_samples_leaf 등.\n",
    "''',\n",
    "'''\n",
    "**Random Forest:**\n",
    "\n",
    "**설명:** Random Forest는 여러 개의 의사 결정 트리를 구성하고 각 트리의 예측을 결합하여 더 강력하고 안정적인 모델을 형성하는 앙상블 학습 방법입니다. 각 트리는 부트스트랩 샘플링을 통해 데이터의 일부를 사용하며, 무작위로 선택된 특징들을 사용하여 높은 다양성을 유지합니다.\n",
    "\n",
    "**하이퍼파라미터:** n_estimators, max_depth, min_samples_split 등.\n",
    "\n",
    "''',\n",
    "'''\n",
    "**Voting:**\n",
    "\n",
    "**설명:** Voting은 여러 개의 다른 머신러닝 모델을 조합하여 높은 성능의 앙상블 모델을 형성하는 앙상블 학습 방법 중 하나입니다. 여러 모델의 예측을 조합함으로써 개별 모델의 약점을 상쇄하고, 전체적인 성능을 향상시킬 수 있습니다. Voting은 주로 분류(Classification) 및 회귀(Regression) 문제에 사용됩니다.\n",
    "\n",
    "**하드 보팅(Hard Voting):** 다수결 원칙을 적용하여 각 모델의 예측 중 가장 많이 선택된 클래스나 값으로 최종 예측을 수행합니다.\n",
    "\n",
    "**소프트 보팅(Soft Voting):** 각 모델의 예측에 가중치를 부여하여 조합하며, 가중 평균을 계산하여 최종 예측을 수행합니다. 이는 모델의 예측에 대한 확률이나 신뢰도 정보를 활용하는 방식입니다.\n",
    "\n",
    "**하이퍼파라미터:** Voting은 다양한 모델을 조합하기 때문에 각 모델의 하이퍼파라미터를 설정해야 하며, 가중치를 조절하는 등의 하이퍼파라미터도 있을 수 있습니다.\n",
    "''']\n",
    "\n",
    "for i in hamburger:\n",
    "    if i ==\"\\n\":\n",
    "        print()\n",
    "    else :print(i, end=\"\",sep=\"\")\n",
    "    \n",
    "\n",
    "while True:\n",
    "    print(\"====================================================================================\") # 모델 선택    \n",
    "    print(\"종료키 : 0\")\n",
    "\n",
    "    print(\"사용할 모델을 선택하세요~\")\n",
    "    for i in range(len(model_list)):\n",
    "        print(f\"{i+1}. {model_list[i]}\")\n",
    "    print(\"====================================================================================\")\n",
    "    model_num=int(input(\"모델 번호를 입력하세요. : \"))\n",
    "    os.system('cls')\n",
    "    if not model_num:\n",
    "        break\n",
    "    print(\"====================================================================================\") # 모델 설명\n",
    "    print(model_text[model_num-1])\n",
    "    yesno=int(input(\"해당 모델을 사용하시겠습니까? (예:1/아니오:0) :\"))\n",
    "    os.system('cls')\n",
    "    if yesno :\n",
    "        break\n",
    "    if not yesno:\n",
    "        continue\n",
    "try :\n",
    "    df=pd.read_csv('./Hamburger.csv')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "print(f\"{model_list[model_num-1]}모델 불러오기...(성공!)\")\n",
    "\n",
    "model_file=f\"./model/{model_list[model_num-1]}.pkl\"\n",
    "try :\n",
    "    model=load(model_file)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# 입력순서 : 소금, 설탕, 지방, 단백질\n",
    "# 섭취량 기준 : https://www.khidi.or.kr/kps/dhraStat/result5?menuId=MENU01657&siteId=SITE00002\n",
    "# 설탕 섭취량 : https://feelgoodpal.com/ko/blog/how-much-sugar-per-day/\n",
    "# =======================================================================\n",
    "#   소금                설탕                   지방         단백질        =\n",
    "#  3299.0        여자(25), 남자(37.5)         47.85       72.4(38.56)    = \n",
    "# =======================================================================\n",
    "\n",
    "# 남자 기준 섭취량 : 2500\n",
    "# 여자 기분 섭취량 : 1800\n",
    "\n",
    "# 한 끼 식사량 : 1/3\n",
    "# 한 끼 칼로리 섭취량(남자) : 2500/3\n",
    "# 한 끼 칼로리 섭취량(여자) : 1800/3\n",
    "# 감자튀김 평균 칼로리 : 250~300\n",
    "# 음료수 평균 칼로리 : 0~50\n",
    "\n",
    "# 적정 칼로리 섭취량(남자) : 2500/3 - (250~300) - (0~50) = 480~580Kcal 정도, 감자튀김을 포기하면 780~880Kcal 정도\n",
    "# 적정 칼로리 섭취량(여자) : 1800/3 - (250~300) - (0~50) = 250~350Kcal 정도, 감자튀김을 포기하면 550~650Kcal 정도 \n",
    "\n",
    "\n",
    "\n",
    "print(\"====================================================================================\") # 입력파트 \n",
    "gender=int(input(\"성별을 입력하세요(남자:0/여자:1) : \")) # 성별에 따라 일일섭취량이 정해져있으므로, 성별에 따라 섭취량을 다르게 설정\n",
    "print(\"====================================================================================\")\n",
    "if gender in [0,1]:\n",
    "    sugar=int(input(\"얼마나 달달한게 땡기시나요?(1~10) :  \"))\n",
    "    if gender :\n",
    "        sugar=sugar*25/10\n",
    "    else :\n",
    "        sugar=sugar*37.5/10              # 1. 설탕 입력\n",
    "else :\n",
    "    print(\"잘못된 입력입니다.\")\n",
    "    sugar=15\n",
    "    \n",
    "# 2. 소금 입력\n",
    "salt=int(input(\"얼마나 짭짤한게 떙기시나요?(1~10) : \"))\n",
    "salt=salt*3299/10\n",
    "\n",
    "# 3. 지방 입력\n",
    "fat=int(input(\"얼마나 기름진 게 땡기시나요?(1~10) : \"))\n",
    "fat=fat*47.85/10\n",
    "\n",
    "# 4. 단백질 입력\n",
    "protein=int(input(\"얼마나 단백질이 땡기시나요?(1~10) : \"))\n",
    "protein=protein*38.56/10\n",
    "os.system('cls')\n",
    "print(\"====================================================================================\")\n",
    "if model_num <9 : \n",
    "    data=pd.DataFrame([[salt, sugar, fat, protein]], columns=[\"sodium\", \"sugar\", \"total_fat\", \"protein\"])\n",
    "elif model_num >=9 :\n",
    "    data=pd.DataFrame(scaler.transform([[salt, sugar, fat, protein]]), columns=[\"sodium\", \"sugar\", \"total_fat\", \"protein\"])\n",
    "\n",
    "\n",
    "cal=model.predict(data)\n",
    "res=df[(df[\"calories\"] <= cal[0]+10) & (df[\"calories\"]>=cal[0]-10)]\n",
    "res.sort_values(by=\"restaurant\", ascending=True).reset_index(drop=True)\n",
    "print(f\"총 {res.shape[0]}건의 음식이 검색되었습니다! \")\n",
    "\n",
    "\n",
    "print(\"====================================================================================\") # 정렬파트 \n",
    "# 정렬방식 선택\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Restaurant                                                    Item                                                  Calories \n",
      "    Subway                                        Footlong Big Philly Cheesesteak                                        1000.0\n",
      "  Burger King                                       Bacon & Swiss Sourdough King                                         1000.0\n",
      "  Burger King                                          Jalapeno King Sandwich                                             990.0\n",
      "  Burger King                                         DOUBLE WHOPPER w/ Cheese                                            990.0\n",
      "  Dairy Queen                                    1/2 lb. FlameThrower® GrillBurger                                       1000.0\n",
      "   McDonalds                        Big Breakfast with Hotcakes and Egg Whites (Regular Biscuit)                          990.0\n",
      "     Sonic                                    Buffalo Dunked Ultimate Chicken Sandwich                                   1000.0\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "sort_num = (int(input(\"1. 짭짤함 \\n2. 달달함 \\n3. 기름짐 \\n4. 단백질 : \")))\n",
    "res=res.sort_values(by=[\"sodium\",\"sugar\",\"total_fat\",\"protein\"][sort_num-1], ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(f\"{'Restaurant':^15} {'Item':^100} {'Calories':^10}\")\n",
    "for index, row in res[[\"restaurant\",\"item\",\"calories\"]].iterrows():\n",
    "    restaurant = row['restaurant'].strip()\n",
    "    item = row['item'].strip()\n",
    "    calories = row['calories']\n",
    "    \n",
    "    print(f\"{restaurant:^15} {item:^100} {calories:10}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_eeb26 thead {\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_eeb26\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_eeb26_level0_col0\" class=\"col_heading level0 col0\" >Name</th>\n",
       "      <th id=\"T_eeb26_level0_col1\" class=\"col_heading level0 col1\" >Age</th>\n",
       "      <th id=\"T_eeb26_level0_col2\" class=\"col_heading level0 col2\" >City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_eeb26_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_eeb26_row0_col0\" class=\"data row0 col0\" >Alice</td>\n",
       "      <td id=\"T_eeb26_row0_col1\" class=\"data row0 col1\" >25</td>\n",
       "      <td id=\"T_eeb26_row0_col2\" class=\"data row0 col2\" >New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eeb26_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_eeb26_row1_col0\" class=\"data row1 col0\" >Bob</td>\n",
       "      <td id=\"T_eeb26_row1_col1\" class=\"data row1 col1\" >30</td>\n",
       "      <td id=\"T_eeb26_row1_col2\" class=\"data row1 col2\" >San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eeb26_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_eeb26_row2_col0\" class=\"data row2 col0\" >Charlie</td>\n",
       "      <td id=\"T_eeb26_row2_col1\" class=\"data row2 col1\" >35</td>\n",
       "      <td id=\"T_eeb26_row2_col2\" class=\"data row2 col2\" >Los Angeles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x26abcf20c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "        'Age': [25, 30, 35],\n",
    "        'City': ['New York', 'San Francisco', 'Los Angeles']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "styled_df = df.style.set_table_styles([\n",
    "        {'selector': 'thead', 'props': [('background-color', 'lightgrey')]}\n",
    "    ])\n",
    "display(styled_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LassoLars(eps=0.01, fit_intercept=False, positive=True, precompute=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LassoLars</label><div class=\"sk-toggleable__content\"><pre>LassoLars(eps=0.01, fit_intercept=False, positive=True, precompute=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LassoLars(eps=0.01, fit_intercept=False, positive=True, precompute=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import load\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "model=load(\"./model/LassoLars.pkl\")\n",
    "df=pd.read_csv(\"./Hamburger.csv\")\n",
    "feature=df[[\"sugar\",\"sodium\",\"total_fat\",\"protein\"]]\n",
    "target=df[\"calories\"]\n",
    "\n",
    "x_train,x_test, y_train,y_test=train_test_split(feature, target, test_size=0.3, random_state=42)\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 12751.61\n",
      "R2 Score: 0.89\n",
      "Mean Absolute Error: 81.79\n",
      "Mean Squared Log Error: 0.25\n",
      "Mean Absolute Percentage Error: 1287151622406620.00\n",
      "Max Error: 521.46\n",
      "Explained Variance Score: 0.90\n",
      "Median Absolute Error: 56.03\n",
      "Mean Poisson Deviance: 27.33\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Mean Tweedie deviance error with power=2 can only be used on strictly positive y and y_pred.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean Gamma Deviance: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_gamma_deviance(y_test,\u001b[38;5;250m \u001b[39my_pred)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean Tweedie Deviance: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_tweedie_deviance(y_test,\u001b[38;5;250m \u001b[39my_pred)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m \u001b[43mprint_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 14\u001b[0m, in \u001b[0;36mprint_metrics\u001b[1;34m(y_test, y_pred)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMedian Absolute Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmedian_absolute_error(y_test,\u001b[38;5;250m \u001b[39my_pred)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean Poisson Deviance: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_poisson_deviance(y_test,\u001b[38;5;250m \u001b[39my_pred)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean Gamma Deviance: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_gamma_deviance(y_test,\u001b[38;5;250m \u001b[39my_pred)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean Tweedie Deviance: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_tweedie_deviance(y_test,\u001b[38;5;250m \u001b[39my_pred)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\EXAM_ML\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\EXAM_ML\\lib\\site-packages\\sklearn\\metrics\\_regression.py:1268\u001b[0m, in \u001b[0;36mmean_gamma_deviance\u001b[1;34m(y_true, y_pred, sample_weight)\u001b[0m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m   1228\u001b[0m     {\n\u001b[0;32m   1229\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1234\u001b[0m )\n\u001b[0;32m   1235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean_gamma_deviance\u001b[39m(y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Mean Gamma deviance regression loss.\u001b[39;00m\n\u001b[0;32m   1237\u001b[0m \n\u001b[0;32m   1238\u001b[0m \u001b[38;5;124;03m    Gamma deviance is equivalent to the Tweedie deviance with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;124;03m    1.0568...\u001b[39;00m\n\u001b[0;32m   1267\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmean_tweedie_deviance\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\EXAM_ML\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:184\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    186\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    188\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\EXAM_ML\\lib\\site-packages\\sklearn\\metrics\\_regression.py:1174\u001b[0m, in \u001b[0;36mmean_tweedie_deviance\u001b[1;34m(y_true, y_pred, sample_weight, power)\u001b[0m\n\u001b[0;32m   1171\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m power \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1172\u001b[0m     \u001b[38;5;66;03m# Gamma and Extreme stable distribution, y and y_pred > 0\u001b[39;00m\n\u001b[0;32m   1173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (y_true \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39many() \u001b[38;5;129;01mor\u001b[39;00m (y_pred \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m-> 1174\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrictly positive y and y_pred.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# pragma: nocover\u001b[39;00m\n\u001b[0;32m   1176\u001b[0m     \u001b[38;5;66;03m# Unreachable statement\u001b[39;00m\n\u001b[0;32m   1177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Mean Tweedie deviance error with power=2 can only be used on strictly positive y and y_pred."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_squared_log_error, mean_absolute_percentage_error, max_error, explained_variance_score, median_absolute_error, mean_poisson_deviance, mean_gamma_deviance, mean_tweedie_deviance\n",
    "\n",
    "# 해당 평가 지표를 모두 출력, 소수점 두 자리로 간격을 일정하기 주어서 출력\n",
    "def print_metrics(y_test, y_pred):\n",
    "    print(f\"Mean Squared Error: {mean_squared_error(y_test, y_pred):.2f}\")\n",
    "    print(f\"R2 Score: {r2_score(y_test, y_pred):.2f}\")\n",
    "    print(f\"Mean Absolute Error: {mean_absolute_error(y_test, y_pred):.2f}\")\n",
    "    print(f\"Mean Squared Log Error: {mean_squared_log_error(y_test, y_pred):.2f}\")\n",
    "    print(f\"Mean Absolute Percentage Error: {mean_absolute_percentage_error(y_test, y_pred):.2f}\")\n",
    "    print(f\"Max Error: {max_error(y_test, y_pred):.2f}\")\n",
    "    print(f\"Explained Variance Score: {explained_variance_score(y_test, y_pred):.2f}\")\n",
    "    print(f\"Median Absolute Error: {median_absolute_error(y_test, y_pred):.2f}\")\n",
    "    print(f\"Mean Poisson Deviance: {mean_poisson_deviance(y_test, y_pred):.2f}\")\n",
    "    print(f\"Mean Gamma Deviance: {mean_gamma_deviance(y_test, y_pred):.2f}\")\n",
    "    print(f\"Mean Tweedie Deviance: {mean_tweedie_deviance(y_test, y_pred):.2f}\")\n",
    "print_metrics(y_test, model.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "model=load(\"./model/LassoLars.pkl\")\n",
    "\n",
    "df=pd.read_csv(\"./Hamburger.csv\")\n",
    "feature=df[[\"sugar\",\"sodium\",\"total_fat\",\"protein\"]]\n",
    "target=df[\"calories\"]\n",
    "\n",
    "x_train,x_test, y_train,y_test=train_test_split(feature, target, test_size=0.3, random_state=42)\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "new_data = [[10,1345,13,37]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\EXAM_ML\\lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but LassoLars was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([534.46475439])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EXAM_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
