{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df=pd.read_csv(\"Hamburger.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Lasso', <class 'sklearn.linear_model._coordinate_descent.Lasso'>)\n",
      "('LassoCV', <class 'sklearn.linear_model._coordinate_descent.LassoCV'>)\n",
      "('LassoLars', <class 'sklearn.linear_model._least_angle.LassoLars'>)\n",
      "('LassoLarsCV', <class 'sklearn.linear_model._least_angle.LassoLarsCV'>)\n",
      "('LassoLarsIC', <class 'sklearn.linear_model._least_angle.LassoLarsIC'>)\n",
      "('MultiTaskLasso', <class 'sklearn.linear_model._coordinate_descent.MultiTaskLasso'>)\n",
      "('MultiTaskLassoCV', <class 'sklearn.linear_model._coordinate_descent.MultiTaskLassoCV'>)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.discovery import all_estimators\n",
    "# 다음 4개에 대해서 진행! \n",
    "estimators=all_estimators(type_filter='regressor')\n",
    "for i in estimators:\n",
    "    if \"Lasso\" in i[0] :\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위의 Lasso들을 모두 import\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.linear_model import LassoLarsCV\n",
    "from sklearn.linear_model import LassoLarsIC\n",
    "from sklearn.linear_model import MultiTaskLasso\n",
    "from sklearn.linear_model import MultiTaskLassoCV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV # 최적의 파라미터를 찾기 위한 그리드서치 및 기타 기능 import\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model,filename):\n",
    "    import joblib\n",
    "    import os\n",
    "    model_dir='./model/'\n",
    "    model_filename=model_dir+f'{filename}.pkl'\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    joblib.dump(model.best_estimator_, model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature=df[[\"sodium\",\"sugar\",\"total_fat\",\"protein\"]]\n",
    "target=df[\"calories\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.8645625728056143 0.8590083537852139\n",
      "28 0.8662447125704024 0.8568647850792414\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m x_train,x_test,y_train,y_test\u001b[38;5;241m=\u001b[39mtrain_test_split(feature,target,test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m,random_state\u001b[38;5;241m=\u001b[39mi)\n\u001b[0;32m      6\u001b[0m model\u001b[38;5;241m=\u001b[39mLasso()\n\u001b[1;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m res1 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mscore(x_train,y_train)\n\u001b[0;32m      9\u001b[0m res2 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mscore(x_test,y_test)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\EXAM_ML\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\EXAM_ML\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:964\u001b[0m, in \u001b[0;36mElasticNet.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    955\u001b[0m     \u001b[38;5;66;03m# Note: Alternatively, we could also have rescaled alpha instead\u001b[39;00m\n\u001b[0;32m    956\u001b[0m     \u001b[38;5;66;03m# of sample_weight:\u001b[39;00m\n\u001b[0;32m    957\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    961\u001b[0m \u001b[38;5;66;03m# X and y will be rescaled if sample_weight is not None, order='F'\u001b[39;00m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;66;03m# ensures that the returned X and y are still F-contiguous.\u001b[39;00m\n\u001b[0;32m    963\u001b[0m should_copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m X_copied\n\u001b[1;32m--> 964\u001b[0m X, y, X_offset, y_offset, X_scale, precompute, Xy \u001b[38;5;241m=\u001b[39m \u001b[43m_pre_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecompute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshould_copy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;66;03m# coordinate descent needs F-ordered arrays and _pre_fit might have\u001b[39;00m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;66;03m# called _rescale_data\u001b[39;00m\n\u001b[0;32m    977\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_input \u001b[38;5;129;01mor\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\EXAM_ML\\lib\\site-packages\\sklearn\\linear_model\\_base.py:856\u001b[0m, in \u001b[0;36m_pre_fit\u001b[1;34m(X, y, Xy, precompute, normalize, fit_intercept, copy, check_input, sample_weight)\u001b[0m\n\u001b[0;32m    845\u001b[0m     X, y, X_offset, y_offset, X_scale \u001b[38;5;241m=\u001b[39m _preprocess_data(\n\u001b[0;32m    846\u001b[0m         X,\n\u001b[0;32m    847\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    852\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    853\u001b[0m     )\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# copy was done in fit if necessary\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m     X, y, X_offset, y_offset, X_scale \u001b[38;5;241m=\u001b[39m \u001b[43m_preprocess_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    865\u001b[0m     \u001b[38;5;66;03m# Rescale only in dense case. Sparse cd solver directly deals with\u001b[39;00m\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;66;03m# sample_weight.\u001b[39;00m\n\u001b[0;32m    867\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    868\u001b[0m         \u001b[38;5;66;03m# This triggers copies anyway.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\EXAM_ML\\lib\\site-packages\\sklearn\\linear_model\\_base.py:264\u001b[0m, in \u001b[0;36m_preprocess_data\u001b[1;34m(X, y, fit_intercept, normalize, copy, copy_y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    261\u001b[0m         X_offset \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[0;32m    263\u001b[0m     X_offset \u001b[38;5;241m=\u001b[39m X_offset\u001b[38;5;241m.\u001b[39mastype(X\u001b[38;5;241m.\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 264\u001b[0m     X \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m X_offset\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalize:\n\u001b[0;32m    267\u001b[0m     X_var \u001b[38;5;241m=\u001b[39m X_var\u001b[38;5;241m.\u001b[39mastype(X\u001b[38;5;241m.\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Lasso : https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso\n",
    "test_max=0\n",
    "train_max=0\n",
    "for i in range(1000):\n",
    "    x_train,x_test,y_train,y_test=train_test_split(feature,target,test_size=0.3,random_state=i)\n",
    "    model=Lasso()\n",
    "    model.fit(x_train,y_train)\n",
    "    res1 = model.score(x_train,y_train)\n",
    "    res2 = model.score(x_test,y_test)\n",
    "    if np.abs(res1-res2) < 0.01 and res1 > train_max:\n",
    "        train_max=res1\n",
    "        test_max=res2\n",
    "        print(i,train_max, test_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'alpha': 1.5, 'max_iter': 10000, 'positive': True, 'selection': 'random', 'tol': 0.01}\n",
      "Model score on test data: 0.8535480908562916\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(feature, target, test_size=0.3, random_state=872)\n",
    "param_grid = {\n",
    "    \"alpha\": [0.1, 0.5, 1.0, 1.5, 2.0],\n",
    "    \"max_iter\": [1000, 5000, 10000],\n",
    "    \"tol\": [0.0001, 0.001, 0.01],\n",
    "    \"selection\": [\"cyclic\", \"random\"],\n",
    "    \"positive\": [True, False]\n",
    "}\n",
    "model = GridSearchCV(Lasso(), param_grid=param_grid, cv=5)\n",
    "model.fit(x_train, y_train)\n",
    "# 최적의 하이퍼 파라미터 출력\n",
    "print(\"Best hyperparameters:\", model.best_params_)\n",
    "# 테스트 데이터로 모델 평가\n",
    "score = model.score(x_test, y_test)\n",
    "print(\"Model score on test data:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, \"Lasso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.8607554777191857 0.8516495274996406\n",
      "5 0.8619842448865522 0.8525993809568189\n",
      "32 0.8626519057761934 0.8556169521026503\n",
      "110 0.8642731785407494 0.8594226072918228\n",
      "797 0.8643966009580126 0.8546396927085064\n",
      "974 0.8649196790973666 0.8559656903908645\n"
     ]
    }
   ],
   "source": [
    "# LassoCV : https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html#sklearn.linear_model.LassoCV\n",
    "test_max=0\n",
    "train_max=0\n",
    "for i in range(1000):\n",
    "    x_train,x_test,y_train,y_test=train_test_split(feature,target,test_size=0.3,random_state=i)\n",
    "    model=LassoCV()\n",
    "    model.fit(x_train,y_train)\n",
    "    res1 = model.score(x_train,y_train)\n",
    "    res2 = model.score(x_test,y_test)\n",
    "    if np.abs(res1-res2) < 0.01 and res1 > train_max:\n",
    "        train_max=res1\n",
    "        test_max=res2\n",
    "        print(i,train_max, test_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'alphas': [0.1, 0.01, 0.001], 'eps': 0.0001, 'fit_intercept': False, 'positive': True, 'precompute': 'auto', 'selection': 'random', 'tol': 0.001}\n",
      "Model score on test data: 0.8535573177675566\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(feature, target, test_size=0.3, random_state=974)\n",
    "param_grid = {\n",
    "    'eps': [1e-2, 1e-3, 1e-4],  # eps 값의 후보\n",
    "    'alphas': [None, [0.1, 0.01, 0.001]],  # 알파 값의 리스트\n",
    "    'fit_intercept': [True, False],  # 절편을 계산할지 여부\n",
    "    'precompute': ['auto', True, False],  # 미리 계산된 Gram 행렬을 사용할지 여부\n",
    "    'tol': [1e-3, 1e-4, 1e-5],  # 수렴 기준\n",
    "    'positive': [True, False],  # 회귀 계수를 양수로 제한할지 여부\n",
    "    'selection': ['cyclic', 'random']  # feature 업데이트 방식\n",
    "}\n",
    "model = GridSearchCV(LassoCV(), param_grid=param_grid, cv=5)\n",
    "model.fit(x_train, y_train)\n",
    "# 최적의 하이퍼 파라미터 출력\n",
    "print(\"Best hyperparameters:\", model.best_params_)\n",
    "# 테스트 데이터로 모델 평가\n",
    "score = model.score(x_test, y_test)\n",
    "print(\"Model score on test data:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, \"LassoCV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8561660250176204 0.882506728306845\n",
      "3 0.8499150000486391 0.8899332401829739\n",
      "12 0.8464870167676537 0.8980977872644373\n",
      "31 0.8293136934894153 0.8985628901278372\n",
      "39 0.8412577086401332 0.899674286266148\n",
      "93 0.840141484308524 0.9023012709802588\n",
      "358 0.8465029972645741 0.9065296863740122\n"
     ]
    }
   ],
   "source": [
    "# LassoLars : https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoLars.html#sklearn.linear_model.LassoLars\n",
    "test_max=0\n",
    "train_max=0\n",
    "for i in range(1000):\n",
    "    x_train,x_test,y_train,y_test=train_test_split(feature,target,test_size=0.3,random_state=i)\n",
    "    model=LassoLars()\n",
    "    model.fit(x_train,y_train)\n",
    "    res1 = model.score(x_train,y_train)\n",
    "    res2 = model.score(x_test,y_test)\n",
    "    if res2 > test_max:\n",
    "        train_max=res1\n",
    "        test_max=res2\n",
    "        print(i,train_max, test_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'eps': 0.01, 'fit_intercept': False, 'positive': True, 'precompute': False}\n",
      "Model score on test data: 0.9056713898137765\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(feature, target, test_size=0.3, random_state=358)\n",
    "param_grid = {\n",
    "    'eps': [1e-2, 1e-3, 1e-4],  # eps 값의 후보\n",
    "    'fit_intercept': [True, False],  # 절편을 계산할지 여부\n",
    "    'precompute': ['auto', True, False],  # 미리 계산된 Gram 행렬을 사용할지 여부\n",
    "    'positive': [True, False],  # 회귀 계수를 양수로 제한할지 여부\n",
    "}\n",
    "model = GridSearchCV(LassoLars(), param_grid=param_grid, cv=5)\n",
    "model.fit(x_train, y_train)\n",
    "# 최적의 하이퍼 파라미터 출력\n",
    "print(\"Best hyperparameters:\", model.best_params_)\n",
    "# 테스트 데이터로 모델 평가\n",
    "score = model.score(x_test, y_test)\n",
    "print(\"Model score on test data:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, \"LassoLars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 일시 중지\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8645626461392588 0.8590189139309868\n",
      "0.8662447925771448 0.8568797559066781\n"
     ]
    }
   ],
   "source": [
    "# LassoLarsCV : https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoLarsCV.html#sklearn.linear_model.LassoLarsCV\n",
    "test_max=0\n",
    "train_max=0\n",
    "for i in range(1000):\n",
    "    x_train,x_test,y_train,y_test=train_test_split(feature,target,test_size=0.3,random_state=i)\n",
    "    model=LassoLarsCV()\n",
    "    model.fit(x_train,y_train)\n",
    "    res1 = model.score(x_train,y_train)\n",
    "    res2 = model.score(x_test,y_test)\n",
    "    if np.abs(res1-res2) < 0.01 and res1 > train_max:\n",
    "        train_max=res1\n",
    "        test_max=res2\n",
    "        print(train_max, test_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8645626461392588 0.8590189139309868\n",
      "0.8662447925771448 0.8568797559066781\n"
     ]
    }
   ],
   "source": [
    "# LassoLarsIC : https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoLarsIC.html#sklearn.linear_model.LassoLarsIC\n",
    "test_max=0\n",
    "train_max=0\n",
    "for i in range(1000):\n",
    "    x_train,x_test,y_train,y_test=train_test_split(feature,target,test_size=0.3,random_state=i)\n",
    "    model=LassoLarsIC()\n",
    "    model.fit(x_train,y_train)\n",
    "    res1 = model.score(x_train,y_train)\n",
    "    res2 = model.score(x_test,y_test)\n",
    "    if np.abs(res1-res2) < 0.01 and res1 > train_max:\n",
    "        train_max=res1\n",
    "        test_max=res2\n",
    "        print(train_max, test_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8645626391446695 0.8590161721896995\n",
      "0.8662447847685604 0.8568746260566804\n"
     ]
    }
   ],
   "source": [
    "# ElasticNet : https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html#sklearn.linear_model.ElasticNet\n",
    "from sklearn.linear_model import ElasticNet\n",
    "test_max=0\n",
    "train_max=0\n",
    "for i in range(1000):\n",
    "    x_train,x_test,y_train,y_test=train_test_split(feature,target,test_size=0.3,random_state=i)\n",
    "    model=ElasticNet(alpha=0.1)\n",
    "    model.fit(x_train,y_train)\n",
    "    res1 = model.score(x_train,y_train)\n",
    "    res2 = model.score(x_test,y_test)\n",
    "    if np.abs(res1-res2) < 0.01 and res1 > train_max:\n",
    "        train_max=res1\n",
    "        test_max=res2\n",
    "        print(train_max, test_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EXAM_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
